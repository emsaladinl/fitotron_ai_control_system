{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19acad0a",
   "metadata": {},
   "source": [
    "# 03 Forecast Train - Entrenamiento del Modelo Predictivo\n",
    "\n",
    "Este notebook entrena el modelo LSTM para predecir el estado futuro del Fitotron.\n",
    "1. Carga datos procesados.\n",
    "2. Genera secuencias temporales (X, y) usando `FeatureBuilder`.\n",
    "3. Entrena el modelo `ForecasterLSTM`.\n",
    "4. Evalua el rendimiento y guarda el modelo.\n",
    "\n",
    "**Entradas:** `data/processed/processed_*.csv`\n",
    "**Salidas:** `models/forecaster_lstm.keras`, `models/stats_forecast.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c441218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T11:34:01.517864Z",
     "iopub.status.busy": "2025-12-08T11:34:01.517864Z",
     "iopub.status.idle": "2025-12-08T11:34:04.671959Z",
     "shell.execute_reply": "2025-12-08T11:34:04.670948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos: C:\\Users\\willy\\Documents\\GitHub\\fitotron_ai_control_system\\fitotron_ai\\models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configurar rutas relativas\n",
    "current_dir = os.getcwd()\n",
    "repo_root = os.path.abspath(os.path.join(current_dir, \"..\", \"..\"))\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "from fitotron_ai.features.feature_builder import FeatureBuilder\n",
    "from fitotron_ai.models.forecaster_lstm import ForecasterLSTM\n",
    "\n",
    "# Directorios\n",
    "PROCESSED_DIR = os.path.join(repo_root, \"data\", \"processed\")\n",
    "MODELS_DIR = os.path.join(repo_root, \"fitotron_ai\", \"models\")\n",
    "RESULTS_DIR = os.path.join(repo_root, \"results\")\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Modelos: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73e127b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T11:34:04.675010Z",
     "iopub.status.busy": "2025-12-08T11:34:04.674002Z",
     "iopub.status.idle": "2025-12-08T11:34:04.680517Z",
     "shell.execute_reply": "2025-12-08T11:34:04.680008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay datos procesados.\n"
     ]
    }
   ],
   "source": [
    "# 1. Cargar Datos Procesados\n",
    "processed_files = glob.glob(os.path.join(PROCESSED_DIR, \"processed_*.csv\"))\n",
    "processed_files.sort(key=os.path.getmtime, reverse=True)\n",
    "\n",
    "target_file = processed_files[0] if processed_files else None\n",
    "df = None\n",
    "\n",
    "if target_file:\n",
    "    print(f\"Cargando: {target_file}\")\n",
    "    df = pd.read_csv(target_file)\n",
    "    if \"timestamp\" in df.columns:\n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "        df.set_index(\"datetime\", inplace=True)\n",
    "else:\n",
    "    print(\"No hay datos procesados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e61e8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T11:34:04.684037Z",
     "iopub.status.busy": "2025-12-08T11:34:04.683026Z",
     "iopub.status.idle": "2025-12-08T11:34:04.691810Z",
     "shell.execute_reply": "2025-12-08T11:34:04.690798Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Construir Features (Secuencias)\n",
    "if df is not None:\n",
    "    # Configuracion\n",
    "    WINDOW_SIZE = 60  # 1 minuto historia\n",
    "    HORIZON = 60      # 1 minuto futuro\n",
    "    VARIABLES = [\"temp\", \"rh\", \"co2\", \"soil\", \"ph\", \"ec\", \"par\"]\n",
    "    \n",
    "    # Filtrar variables disponibles\n",
    "    available_vars = [v for v in VARIABLES if v in df.columns]\n",
    "    print(f\"Variables usadas: {available_vars}\")\n",
    "    \n",
    "    builder = FeatureBuilder(\n",
    "        window_size=WINDOW_SIZE,\n",
    "        horizon=HORIZON,\n",
    "        variables=available_vars,\n",
    "        db_path=\"\" # No usado cuando pasamos df directo\n",
    "    )\n",
    "    \n",
    "    # Inyectar datos manualmente al builder\n",
    "    # (FeatureBuilder espera cargar el mismo, pero usamos make_sequences con df)\n",
    "    builder.data = df[available_vars].interpolate().dropna()\n",
    "    \n",
    "    try:\n",
    "        X, y = builder.make_sequences(builder.data)\n",
    "        X_norm, y_norm = builder.normalize(X, y, fit=True)\n",
    "        \n",
    "        print(f\"Secuencias generadas: X={X_norm.shape}, y={y_norm.shape}\")\n",
    "        \n",
    "        # Guardar stats de normalizacion\n",
    "        stats_path = os.path.join(MODELS_DIR, \"stats_forecast.json\")\n",
    "        # Convertir numpy a lista para JSON\n",
    "        serializable_stats = {}\n",
    "        for k, v in builder.norm_stats.items():\n",
    "            if isinstance(v, np.ndarray):\n",
    "                serializable_stats[k] = v.tolist()\n",
    "            else:\n",
    "                serializable_stats[k] = v\n",
    "        \n",
    "        with open(stats_path, \"w\") as f:\n",
    "            json.dump(serializable_stats, f, indent=4)\n",
    "        print(f\"Stats guardados en: {stats_path}\")\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"Error generando secuencias: {e}\")\n",
    "        X_norm, y_norm = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee59611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T11:34:04.693870Z",
     "iopub.status.busy": "2025-12-08T11:34:04.693870Z",
     "iopub.status.idle": "2025-12-08T11:34:04.701516Z",
     "shell.execute_reply": "2025-12-08T11:34:04.700505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos insuficientes para entrenar.\n"
     ]
    }
   ],
   "source": [
    "# 3. Entrenar Modelo\n",
    "if 'X_norm' in locals() and X_norm is not None and len(X_norm) > 100:\n",
    "    # Split Train/Test (80/20)\n",
    "    split_idx = int(len(X_norm) * 0.8)\n",
    "    X_train, X_test = X_norm[:split_idx], X_norm[split_idx:]\n",
    "    y_train, y_test = y_norm[:split_idx], y_norm[split_idx:]\n",
    "    \n",
    "    forecaster = ForecasterLSTM(\n",
    "        input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "        output_dim=y_train.shape[1],\n",
    "        hidden_units=64,\n",
    "        dropout=0.2\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        forecaster.build_model()\n",
    "        history = forecaster.train(\n",
    "            X_train, y_train,\n",
    "            X_val=X_test, y_val=y_test,\n",
    "            epochs=20,\n",
    "            batch_size=32,\n",
    "            patience=5\n",
    "        )\n",
    "        \n",
    "        # Guardar modelo\n",
    "        model_path = os.path.join(MODELS_DIR, \"forecaster_lstm.keras\")\n",
    "        forecaster.save(model_path)\n",
    "        print(f\"Modelo entrenado guardado en: {model_path}\")\n",
    "        \n",
    "        # Guardar metricas CSV\n",
    "        metrics_df = pd.DataFrame(history.history)\n",
    "        metrics_path = os.path.join(RESULTS_DIR, \"forecast_metrics.csv\")\n",
    "        metrics_df.to_csv(metrics_path, index=False)\n",
    "        print(f\"Metricas guardadas en: {metrics_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error en entrenamiento: {e}\")\n",
    "else:\n",
    "    print(\"Datos insuficientes para entrenar.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
